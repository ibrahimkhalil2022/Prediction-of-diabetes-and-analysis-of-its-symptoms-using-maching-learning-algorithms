#!/usr/bin/env python
# coding: utf-8

# # Actual Prediction

# In[1]:


import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for visualization and plot
import csv,sklearn

from subprocess import check_output


# #### Merge data (predicted and actual) 

# In[2]:


#glucose and output data
df1 = pd.read_csv('input/diabetestest2.csv',encoding='latin1')

#predicted insulin values
df2 = pd.read_csv('input/diabetespredresult.csv',encoding='latin1')


# In[3]:


#concatenate predicted insulin values with diabetestest2 data (which is only Glucose and Output)
data = pd.concat([df1, df2], axis = 1)

#rearrange columns
data = data[['Glucose','Insulin','Output']]


# In[4]:


#non-zero diabetes data
df3 = pd.read_csv('input/diabetesNonzero.csv',encoding='latin1')
data.head()


# In[5]:


#concatenate predicted and non-zero daibetes data to one frame
frames = [data, df3]

data = pd.concat(frames)
data.head()


# In[6]:


data.describe()
#save final merged data
#convert DataFrame to csv file. NB: index is automatically generated by Pandas while converting to CSV file. So, use index=False to stop it
data.to_csv('input/diabetesmerge.csv', index=False)


# In[7]:


#read again for Classification accuracies
data = pd.read_csv('input/diabetesmerge.csv',encoding='latin1')


# In[8]:


from sklearn.model_selection import train_test_split
splitRatio = 0.2

train , test = train_test_split(data,test_size = splitRatio,random_state = 123)

X_train = train[[x for x in train.columns if x not in ["Output"]]]
y_train = train[["Output"]]

X_test  = test[[x for x in test.columns if x not in ["Output"]]]
y_test  = test[["Output"]]


# In[9]:


from sklearn.model_selection import train_test_split 
#X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)


# In[10]:


from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
model = KNeighborsClassifier()
#model = LogisticRegression()
#model = GaussianNB()
#model =  LinearRegression()

model.fit(X_train,y_train)
prediction = model.predict(X_test)
accuracy_score(y_test,prediction)


# #### Testing with the Unknown 

# In[51]:


#The unknown: given  a person whose Glucose value is 160 and Insulin value is 30
new_df = pd.DataFrame([[160,30]])

# We predict the outcome
prediction = model.predict(new_df)

print(prediction)


# In[52]:


#probability of prediction
new = model.predict_proba(new_df)[:]
msg = ''

if prediction == 0:
    msg = 'Normal'
elif prediction == 1:
    msg = 'Prediabetic'
else:
    msg = 'Diabetic'

Proba = int(((new[:,2])) * 100)
print('Your daibetes status is:' , msg, 'and you have {}%'.format(Proba), 'chances of being diabetic')


# In[ ]:




